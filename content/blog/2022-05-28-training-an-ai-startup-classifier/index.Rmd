---
title: AI company classifier - Getting clean data    
author: Knut JÃ¤gersberg
date: '2022-05-28'
slug: []
categories:
  - Data Science
tags:
  - Natural Language Processing
  - Text Classification
  
output:
  blogdown::html_page:
    toc: true
---



# AI startup classification from company descriptions 

My hypothesis is I can use one sentence descriptions of each company to identify their overall market, for AI trend monitoring from social media and SERPS. The data source:  

https://medium.com/@bootstrappingme/global-artificial-intelligence-landscape-including-database-with-3-465-ai-companies-3bf01a175c5d  


![](startups.png)



## Data preparation

The data only needs minimal cleaning. I will remove the company name. 

```{r}
pacman::p_load(tidyverse, tidytable, openxlsx, qualV)

startups <- openxlsx::read.xlsx("/run/media/knut/HD/MLearningAlgoTests/data/ai_startups.xlsx", sheet = 3) %>% rename(Market=`Category.-.Final`)


head(startups %>% select(Country, Market, Name, Description))

```


Removing company names from descriptions, rough fix. 

```{r}

startups_clean <- startups %>% select(Market, Name, Description) %>% na.omit() %>% mutate(text=tolower(Description), helper_col=tolower(Name))

source("/run/media/knut/HD/MLearningAlgoTests/clean.R")

LCS <- purrr::map2(.x = startups_clean$text, .y = startups_clean$helper_col, .f = PTXQC::LCS) %>% rlist::list.rbind()



startups_clean <- startups_clean %>% mutate(text=clean(str_replace(text, LCS, "Our company")))

startups_clean %>% pull(text) %>% head(10)

```

Check class imbalance. 

```{r}
ggcharts::bar_chart(startups_clean, Market)
```

Eventhough some classes have few records, the data looks good for data augmentation. Skimming it somes some signal in even in classes with few queries, so I will avoid disgarding them. 


```{r}
startups_clean %>% filter(Market%in%c("Manufacturing", "Insurance", "Education", "Energy", "Real Estate")) %>% arrange(Market)
```

## Dataset splitting

Since I compare different approaches (acting like different ML algorithms compared to each other), I need an extra validation split, even if the underlying algorithm makes another validation split in the (balanced) train data: I compare transformer hyperparameter tuning with different intertraining procedures and a combined approach. After I selected the best one, an unbiased estimate comes from a withheld testset.   
I use twinning algorithm (https://arxiv.org/abs/2110.02927) on sentence embeddings for optimal train, validation and test set splitting (75 %, 12.5 %, 12.5 %). Research by the creators of twinning showed the algorithm can improve sampling for tabular data, as it explicitly preserves statistical properties of the splits. This works for precise semantic representations as well. 


```{r, results=FALSE, warning=FALSE, message=FALSE}
library(reticulate)
use_python("/home/knut/transformers/bin/python3", required = T)
  
  
st <- reticulate::import("sentence_transformers")

model <- st$SentenceTransformer('all-mpnet-base-v2')
embeddings = model$encode(startups_clean$text)


library(twinning)

multiplet_idx <- twinning::multiplet(embeddings %>% bind_cols(startups_clean %>% select(Market) %>% mutate(Market=as.factor(Market))), k = 8, strategy = 2)


train = startups_clean[which(multiplet_idx %in% c(1,2,3,4,5,6)), ]
validation = startups_clean[which(multiplet_idx %in% c(7)), ]
test = startups_clean[which(multiplet_idx %in% c(8)), ]


```


## Data augmentation for upsampling


Let's try these tools for data augmentation from the reknown nlpaug library: 
- backtranslation
- roberta word substitutions
- fasttext word substitutions
- synonym substitutions according to wordnet / ppdb 

On top of that we upsample records for the few categories for which a 5 fold is not enough. 



```{r, results=FALSE, warning=FALSE, message=FALSE}

startups_small_cats <- startups_clean %>% group_by(Market) %>% count(sort = T) %>% filter(n<200)
startups_clean_upsample <- train %>% filter(Market%in%startups_small_cats$Market)


library(reticulate)
use_python("/home/knut/transformers/bin/python3", required = T)
  
  
nlpaug <- reticulate::import("nlpaug.augmenter.word")
  
back_translation <- nlpaug$BackTranslationAug(from_model_name = 'facebook/wmt19-en-de', 
                          to_model_name='facebook/wmt19-de-en', device = "cuda")



back_translate <- function(text){back_translation$augment(data = text)}

back_translated <- purrrgress::pro_map(.x = startups_clean_upsample$text, .f = back_translate) %>% rlist::list.rbind()



roberta <- nlpaug$ContextualWordEmbsAug(model_path="roberta-base", action="substitute", aug_max=as.integer(3), device = "cuda")


augment <- function(text){roberta$augment(data = text)}

roberta_augmentation <- purrrgress::pro_map(.x = startups_clean_upsample$text, .f = augment) %>% rlist::list.rbind()


fasttext <- nlpaug$WordEmbsAug(model_type=as.character("fasttext"), model_path=as.character("/home/knut/nlpaug/embs/wiki.en/wiki.en.vec"), action=as.character("substitute"), aug_max=as.integer(3))


augment <- function(text){fasttext$augment(data = text)}

fasttext_augmentation <- purrrgress::pro_map(.x = startups_clean_upsample$text, .f = augment) %>% rlist::list.rbind()


synonym_augmenter_wordnet <- nlpaug$SynonymAug(aug_src='wordnet')

augment <- function(text){synonym_augmenter_wordnet$augment(data = text)}


wordnet_augmentation <- purrrgress::pro_map(.x = startups_clean_upsample$text, .f = augment) %>% rlist::list.rbind()


aug = nlpaug$SynonymAug(aug_src='ppdb', model_path="/home/knut/nlpaug/ppdb-2.0-s-all")
augment <- function(text){aug$augment(data = text)}


ppdb_synonym_augmentation <- purrrgress::pro_map(.x = startups_clean_upsample$text, .f = augment) %>% rlist::list.rbind()


size_largest_category <- train %>% group_by(Market) %>% count(sort = T) %>% ungroup() %>% slice_head(n = 1) %>% pull(n)

train_augmented <- startups_clean_upsample %>% mutate(back_translated=back_translated, roberta_augmentation=roberta_augmentation, fasttext_augmentation=fasttext_augmentation, wordnet_augmentation=wordnet_augmentation, ppdb_synonym_augmentation=ppdb_synonym_augmentation)


train_augmented <- train_augmented %>% select(-helper_col) %>% data.table::melt(id.vars=colnames(train_augmented)[1:3]) %>% rename(text=value)
startups_clean_upsample_no <- train %>% filter(Market%in%startups_small_cats$Market== F)


augmented_dataset <- startups_clean_upsample_no %>% bind_rows(train_augmented)

upsample_dataset <- caret::upSample(startups_clean, startups_clean$Market, list = F)$x

train_upsampled <- augmented_dataset %>% bind_rows(upsample_dataset) %>% group_by(Market) %>% slice_head(n = size_largest_category)


train_upsampled %>% group_by(Market) %>% count(sort = T)
```


## Baseline Model

First we try a simple baseline model. It seems the classes cannot be seperated easily. 

```{r}
classes <- data.frame(labels=startups_clean$Market %>% as.factor() %>% as.numeric() %>% -1, Market=startups_clean$Market) %>% distinct()

ttrain <- train_upsampled %>% ungroup() %>% inner_join(classes) %>% select(text, labels) %>% as.data.frame()

teval <- validation %>% inner_join(classes) %>% select(text, labels)

# fastSave::load.lbzip2("/run/media/knut/HD/MLearningAlgoTests/aistartup")

library(quanteda)
upsampled_dfm <- dfm(ttrain$text)


training_dfm <- dfm(ttrain$text, remove = quanteda::stopwords("english"), stem = TRUE) %>% dfm_tfidf() #%>% dfm_trim(min_termfreq = 3000, termfreq_type = "rank")

eval_dfm <- dfm(teval$text) %>% dfm_match(featnames(training_dfm)) 

model <- quanteda.textmodels::textmodel_nb(x = training_dfm, ttrain$labels)

predictions <- predict(model, eval_dfm) %>% as.data.frame()

evaluation_metrics <- crfsuite::crf_evaluation(teval$labels, predictions$.)

data.frame(mcc=mltools::mcc(teval$labels, predictions$. %>% as.character() %>% as.numeric()), evaluation_metrics$overall %>% t())
```


## Listening to our AI's confusion 


```{r}

eval_labels <- teval %>% inner_join(classes %>% rename(Market_true=Market)) %>% bind_cols(data.table(labels=predictions$. %>% as.character() %>% as.numeric()) %>% inner_join(classes %>% rename(Market_true=Market)))

conf_mat <- cvms::confusion_matrix(teval$labels, predictions$.)

cvms::plot_confusion_matrix(conf_mat$`Confusion Matrix`[[1]])

```





## Conclusion